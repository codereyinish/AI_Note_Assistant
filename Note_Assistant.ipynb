{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6977c24c-cb76-4836-8c58-bdd3f259fe8b",
   "metadata": {},
   "source": [
    "**Problem is  the OpenAI assistant continues to respond in its default style(reads more like something from ChatGPT ) rather than referring to the provided document and tailoring its responses accordingly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ad1fa-1f37-4683-9e5f-ede2895e7dcc",
   "metadata": {},
   "source": [
    "## Knowledge Retrieval\n",
    "Knowledge(Files) + Retrieval Capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da05a461-2161-474b-ab56-b4c97a2c9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# To fetch the API key stored as an environment variable.\n",
    "import os\n",
    "import time\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef56cf4-cff9-466f-8bef-1dc1f3f1706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a vector store\n",
    "vector_store = client.beta.vector_stores.create(name = \"RAG Introduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8378bdc-d542-42ba-b47f-a6a71aaaf752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "#FILE PREPARATION, Upload the files to Vector Stores\n",
    "file_paths = [\"docs/rag.docx\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id,\n",
    "    files=file_streams\n",
    ")\n",
    "print(file_batch.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05be2f98-d2da-483e-b80a-285ab9ad0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3206ec-7035-4898-8e69-cc021e3dd936",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_instructions = \"\"\"MBGPT, functioning as a virtual Notebook Responde on Youtube, communicates in clear, accessible language,escalating to technical depth upon request. \\\n",
    "When asked a question, MBGPT will refer to the content from the provided file 'rag.docx' to retrieve and present the relevant information, instead of generating an answer independently. The answers will be based on the exact content of the file, ensuring accurate and contextually appropriate responses.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7095e8-c019-4d16-bafa-cf559709a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create another assistant(this time with file search capability)\n",
    "assistant = client.beta.assistants.create(\n",
    "    name = \"MBGPT\",\n",
    "    description = \"Document Reader and Responder\",\n",
    "    instructions= new_instructions,\n",
    "    model = \"gpt-4-turbo\",\n",
    "    tools = [{\"type\": \"file_search\"}],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea01f0a3-fd86-48fd-98ff-6f6dc46ff56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the assistant to use the new Vector store so that assistant can access and retrieve(resources) the files in vector store through file_search tools \n",
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id = assistant.id, #who to upadate\n",
    "    tool_resources = {\"file_search\": {\"vector_store_ids\":[vector_store.id]}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e769e20-c491-4e9c-9286-2a1b9c3b6f2f",
   "metadata": {},
   "source": [
    "## Create a Thread\n",
    "Create a message thread and we can also add vector stores to the thread(different from the vector_store assistant uses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a267486-8063-4c62-bf63-9af506ceb22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID: file-h10HPZnQxwClOvusZ4kzmUCQ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message_file = client.files.create(\n",
    "    file = open(\"docs/rag.docx\",\"rb\"),\n",
    "    purpose = \"assistants\"\n",
    ")\n",
    "print(f\"File ID: {message_file.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780c7dd-7320-4cbe-adc0-3a6a2c9d3527",
   "metadata": {},
   "source": [
    "Lets create a message thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f732771-ac4d-46f4-a599-26c2ec6aa10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ce442-fba9-4465-82fd-3d0fd4b32909",
   "metadata": {},
   "source": [
    "A technical question to ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74a4ac1-00ff-49cf-8ea3-9d0434286701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_message = \"What is the problem with OpenAI?\"\n",
    "# ANother question\n",
    "user_message = \"What are the steps in setting up RAG?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d9ebfd-728f-4f8b-b835-e750c5322810",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    content = user_message,\n",
    "    role = \"user\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2acd2c0-709e-4d69-9b8c-0627f548c5c3",
   "metadata": {},
   "source": [
    "## Create a Run\n",
    "Create a run object that will handle the conversation passing between user and assistant in the thread(run uses all tools assigned , adds generated response to thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d7286ce-4769-43f0-8daa-1fa3df78bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id = assistant.id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b2329-6704-459d-aa2a-5608f87e9969",
   "metadata": {},
   "source": [
    "## Retrieve and Print the Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e9e357-d890-4454-8965-1b3b72921589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up RAG consists of several non-trivial steps, as outlined in your document:\n",
      "\n",
      "1. **Chunking Documents**: This involves breaking down the documents into manageable pieces.\n",
      "2. **Setting up Vector Database**: Creating and maintaining a vectorized form of the documents for efficient retrieval.\n",
      "3. **Building Semantic Search Function**: Developing a function to search through the vectorized document database semantically.\n",
      "4. **Fusing Search Results into Context Window**: Integrating the search results into the assistant’s context window for better response generation.\n",
      "\n",
      "In the context of using OpenAI's API, however, some of these steps are simplified. For instance, when you upload your documents to the API:\n",
      "- OpenAI already handles parsing and chunking of documents,\n",
      "- It creates and stores the embeddings automatically,\n",
      "- The API is designed to use both vector and keyword search methods to retrieve relevant content for answering user queries.\n",
      "\n",
      "So, essentially, you only need to upload your documents and enable the retrieval capability on the AI assistant when using OpenAI's API for handling documents【6:0†source】.\n"
     ]
    }
   ],
   "source": [
    "#we have our response added to thread, now retrieve it\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id = thread.id\n",
    ")\n",
    "\n",
    "#Retrieve latest response \n",
    "print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58292072-7cd1-4489-9a1b-28653fe4b004",
   "metadata": {},
   "source": [
    "**YES YES AT least some improvement and I am glad this is reading the question well(going through the keywords) and picking up the content from the mass of the given content**\n",
    "While it seems like it's just retrieving and pasting content, I don't think we can describe it as merely a \"Ctrl F finder.\" Ultimately, it's all about refining the prompt. In this case, we should instruct ChatGPT to not only retrieve content but also to add a bit of its own commentary. It should blend the retrieved information with the original content and respond as if a tutor is addressing a student's queries. Additionally, we should include a few example responses to guide it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833161a7-0942-44db-97a5-f21e4c9de72a",
   "metadata": {},
   "source": [
    "### Clean the Garbage(Delete Stored Files and Vector_Store File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e31b54f-78df-477d-b4cb-bf42902d2b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileDeleted(id='file-h10HPZnQxwClOvusZ4kzmUCQ', deleted=True, object='file')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete the file from storage system\n",
    "client.files.delete(\n",
    "    file_id = message_file.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d50310c-fe00-419a-9f3f-873d4a098a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantDeleted(id='asst_zIaaAlrHTwkHoUueugOS1mva', deleted=True, object='assistant.deleted')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DELETE THE ASSISTANT AFTER USE\n",
    "client.beta.assistants.delete(assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d130b-cb7c-400b-844a-dcddeb79fc85",
   "metadata": {},
   "source": [
    "### HELP ME IF YOU CAN \n",
    "#I tried lot letting user upload file in streamlit and then delivering/uploading it into THEIR opeanAI platform isntead of uploading them locally(which requires more coding knowledge).... We could do it in Whishpher API through file read stream but we cant still directly upload the file directlyu into the OpenAI platform from external source(without going into OpenAI platform) for security reasons rey.\n",
    "https://community.openai.com/t/file-upload-in-openai-platform-from-external-source/840294\n",
    "https://community.openai.com/t/whisper-can-we-transcribe-from-url-and-file-upload/95700/4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
