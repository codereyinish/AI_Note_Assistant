{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6977c24c-cb76-4836-8c58-bdd3f259fe8b",
   "metadata": {},
   "source": [
    "**Problem is  the OpenAI assistant continues to respond in its default style(reads more like something from ChatGPT ) rather than referring to the provided document and tailoring its responses accordingly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ad1fa-1f37-4683-9e5f-ede2895e7dcc",
   "metadata": {},
   "source": [
    "## Knowledge Retrieval\n",
    "Knowledge(Files) + Retrieval Capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da05a461-2161-474b-ab56-b4c97a2c9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# To fetch the API key stored as an environment variable.\n",
    "import os\n",
    "import time\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ef56cf4-cff9-466f-8bef-1dc1f3f1706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a vector store\n",
    "vector_store = client.beta.vector_stores.create(name = \"RAG Introduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8378bdc-d542-42ba-b47f-a6a71aaaf752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "#FILE PREPARATION, Upload the files to Vector Stores\n",
    "file_paths = [\"docs/rag.docx\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "print(file_batch.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05be2f98-d2da-483e-b80a-285ab9ad0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d3206ec-7035-4898-8e69-cc021e3dd936",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_instructions = \"\"\"MBGPT, functioning as a virtual Notebook Responde on Youtube, communicates in clear, accessible language,escalating to technical depth upon request. \\\n",
    "When asked a question, MBGPT will refer to the content from the provided file 'rag.docx' to retrieve and present the relevant information, instead of generating an answer independently. The answers will be based on the exact content of the file, ensuring accurate and contextually appropriate responses.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab7095e8-c019-4d16-bafa-cf559709a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create another assistant(this time with file search capability)\n",
    "assistant = client.beta.assistants.create(\n",
    "    name = \"MBGPT\",\n",
    "    description = \"Document Reader and Responder\",\n",
    "    instructions= new_instructions,\n",
    "    model = \"gpt-4-turbo\",\n",
    "    tools = [{\"type\": \"file_search\"}],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea01f0a3-fd86-48fd-98ff-6f6dc46ff56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the assistant to use the new Vector store so that assistant can access and retrieve(resources) the files in vector store through file_search tools \n",
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id = assistant.id, #who to upadate\n",
    "    tool_resources = {\"file_search\": {\"vector_store_ids\":[vector_store.id]}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e769e20-c491-4e9c-9286-2a1b9c3b6f2f",
   "metadata": {},
   "source": [
    "## Create a Thread\n",
    "Create a message thread and we can also add vector stores to the thread(different from the vector_store assistant uses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a267486-8063-4c62-bf63-9af506ceb22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID: file-CFjTL54QaMCzp7X5foXa6aV5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message_file = client.files.create(\n",
    "    file = open(\"docs/rag.docx\",\"rb\"),\n",
    "    purpose = \"assistants\"\n",
    ")\n",
    "print(f\"File ID: {message_file.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780c7dd-7320-4cbe-adc0-3a6a2c9d3527",
   "metadata": {},
   "source": [
    "Lets create a message thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f732771-ac4d-46f4-a599-26c2ec6aa10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ce442-fba9-4465-82fd-3d0fd4b32909",
   "metadata": {},
   "source": [
    "A technical question to ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c74a4ac1-00ff-49cf-8ea3-9d0434286701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_message = \"What is the problem with OpenAI?\"\n",
    "# ANother question\n",
    "user_message = \"What are the steps in setting up RAG?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19d9ebfd-728f-4f8b-b835-e750c5322810",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    content = user_message,\n",
    "    role = \"user\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2acd2c0-709e-4d69-9b8c-0627f548c5c3",
   "metadata": {},
   "source": [
    "## Create a Run\n",
    "Create a run object that will handle the conversation passing between user and assistant in the thread(run uses all tools assigned , adds generated response to thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d7286ce-4769-43f0-8daa-1fa3df78bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id = assistant.id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b2329-6704-459d-aa2a-5608f87e9969",
   "metadata": {},
   "source": [
    "## Retrieve and Print the Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2e9e357-d890-4454-8965-1b3b72921589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up RAG (Retrieval-Augmented Generation) includes several non-trivial steps, specifically when it is not integrated via the OpenAI API. Here are the key steps involved:\n",
      "\n",
      "1. **Chunking Documents**: This involves dividing large documents into smaller, manageable chunks that are more suitable for processing.\n",
      "2. **Setting up a Vector Database**: This database stores the vector embeddings of the document chunks for quick retrieval.\n",
      "3. **Building a Semantic Search Function**: This function facilitates the searching of relevant document chunks based on the query vector.\n",
      "4. **Fusing Search Results into a Context Window**: This step integrates the retrieved document chunks into the context window for generating responses.\n",
      "\n",
      "When using the OpenAI API, many of these steps are streamlined. The API manages document parsing, chunking, creating embeddings, and storing them. Additionally, it integrates both vector and keyword search capabilities to retrieve content relevant to user queries. The essential steps when using OpenAI's API are:\n",
      "\n",
      "- **Upload Documents for Retrieval**: You need to upload your documents which the API will use for retrieval.\n",
      "- **Add Retrieval Capability to the AI Assistant**: This involves configuring the AI assistant to use the uploaded documents for generating responses【6:0†source】.\n"
     ]
    }
   ],
   "source": [
    "#we have our response added to thread, now retrieve it\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id = thread.id\n",
    ")\n",
    "\n",
    "#Retrieve latest response \n",
    "print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58292072-7cd1-4489-9a1b-28653fe4b004",
   "metadata": {},
   "source": [
    "**YES YES AT least some improvement and I am glad this is reading the question well(going through the keywords) and picking up the content from the mass of the given content**\n",
    "While it seems like it's just retrieving and pasting content, I don't think we can describe it as merely a \"Ctrl F finder.\" Ultimately, it's all about refining the prompt. In this case, we should instruct ChatGPT to not only retrieve content but also to add a bit of its own commentary. It should blend the retrieved information with the original content and respond as if a tutor is addressing a student's queries. Additionally, we should include a few example responses to guide it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
